{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01996b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Tuple\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6116b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ngram:\n",
    "    def __init__(self, n : int, korpus : str, smoothing = False):\n",
    "        self.n                          = n\n",
    "        self.smoothing                  = smoothing\n",
    "        self.toks                       = self._init_toks(korpus)\n",
    "\n",
    "        self.vocab, self.vocab_count    = self._init_vocab()\n",
    "\n",
    "        self.counts                     = self._count()\n",
    "\n",
    "\n",
    "    def _init_toks(self, korpus):\n",
    "        # Alle Interpunktionszeichen außer \\w \\s ; . ? ! entfernen\n",
    "        text_no_p = re.sub(r\"[^\\w\\s;.?!]\", \"\", korpus)\n",
    "        # Leerzeichen vor jedem übrigen Punktionszeichen setzen\n",
    "        text_no_p = re.sub(r\"([;.?!])\", r\" \\1\", text_no_p)\n",
    "\n",
    "        # Satzgrenzen\n",
    "        text_no_p_ends = re.sub(r\"([?!;.])\", r\"\\1 </s>|||<s> \", text_no_p)\n",
    "        text_no_p_ends = \"<s> \" + text_no_p_ends + \" </s>\"\n",
    "\n",
    "        text_no_p_ends = text_no_p_ends.lower()\n",
    "\n",
    "        text_no_p_ends_list = re.findall(r'\\w+|<s>|</s>|[;.!?]', text_no_p_ends)\n",
    "\n",
    "        # Each sentence gets a whole list\n",
    "        toks = []\n",
    "        group = []\n",
    "\n",
    "        for tok in text_no_p_ends_list:\n",
    "            group.append(tok)\n",
    "\n",
    "            if tok == \"</s>\":\n",
    "                toks.append(group)\n",
    "                group = []\n",
    "\n",
    "        return toks\n",
    "\n",
    "    def _init_vocab(self):\n",
    "        # 1) Zähle alle Tokens\n",
    "        counter = Counter(tok for sentence in self.toks for tok in sentence)\n",
    "        \n",
    "        # 2) Sortiere nach Häufigkeit (absteigend)\n",
    "        items = counter.most_common()    # Liste von (token, count)\n",
    "        \n",
    "        # 3) Entpacke in zwei Listen\n",
    "        vocab, counts = zip(*items)\n",
    "        \n",
    "        return list(vocab), list(counts)\n",
    "\n",
    "\n",
    "    def _count(self):\n",
    "        \"\"\"\n",
    "        counts: Dict[ Tuple(context), Counter(next_word → count) ]\n",
    "        \"\"\"\n",
    "        counts = defaultdict(Counter)\n",
    "        for sent in self.toks:\n",
    "            for i in range(len(sent) - self.n + 1):\n",
    "                ctx  = tuple(sent[i:i + (self.n - 1)])\n",
    "                nxt  = sent[i + self.n - 1]\n",
    "                counts[ctx][nxt] += 1\n",
    "\n",
    "        if self.smoothing:\n",
    "            # Add-one Smoothing: für jeden Kontext und jedes Vokabel +1\n",
    "            for ctx in counts:\n",
    "                for w in self.vocab:\n",
    "                    counts[ctx][w] += 1\n",
    "\n",
    "        return counts\n",
    "    \n",
    "\n",
    "    def next_word(self, seed):\n",
    "        \"\"\"\n",
    "        Gibt genau ein Wort zurück\n",
    "        \"\"\"\n",
    "        toks = seed.lower().split()\n",
    "        # Padding mit <s>\n",
    "        while len(toks) < self.n - 1:\n",
    "            toks.insert(0, \"<s>\")\n",
    "        \n",
    "        ctx = tuple(toks[-(self.n - 1):])\n",
    "\n",
    "        # Hol den Counter für diesen Kontext (oder leeren Counter als Fallback)\n",
    "        counter = self.counts.get(ctx, None)\n",
    "        if not counter:\n",
    "            # unbekannter Kontext → gleichverteilt über ganzes Vokabular\n",
    "            return random.choice(self.vocab)\n",
    "\n",
    "        # Liste von möglichen Nachfolgern und ihren Counts\n",
    "        words, weights = zip(*counter.items())\n",
    "\n",
    "        # Nächste wort\n",
    "        return random.choices(words, weights=weights, k=1)[0]\n",
    "\n",
    "    def generate(self, seed: str, length: int) -> str:\n",
    "        toks = seed.lower().split()\n",
    "        # Padding links mit <s>\n",
    "        while self.n > 1 and len(toks) < self.n - 1:\n",
    "            toks.insert(0, \"<s>\")\n",
    "\n",
    "        for _ in range(length):\n",
    "            nxt = self.next_word(\" \".join(toks[-(self.n - 1):]))\n",
    "            toks.append(nxt)\n",
    "            if nxt == \"</s>\":\n",
    "                break\n",
    "\n",
    "        # Gib den Text ohne die Start-Markierungen zurück\n",
    "        return \" \".join(toks)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "736fc19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 10 Random <UNK> for Toks with 1 occourance\n",
    "\n",
    "# for i, (num, word) in enumerate(num_vocab):\n",
    "#     if num == 1:\n",
    "#         begin = i\n",
    "#         break\n",
    "\n",
    "# start_end_indexes = list(range(begin, len(num_vocab)))\n",
    "\n",
    "# choosen = []\n",
    "\n",
    "# for _ in range(10):\n",
    "#     rand_idx = random.choice(start_end_indexes)\n",
    "#     choosen.append(rand_idx)\n",
    "#     start_end_indexes.remove(rand_idx)\n",
    "\n",
    "# for i in choosen:\n",
    "#     num_vocab[i][1] = \"<UNK>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c33ba8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"\"\n",
    "\n",
    "for txt in os.listdir(\"korpus\"):\n",
    "    with open(f\"korpus/{txt}\", \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    raw_text += content + \" \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5197e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "LM1 = ngram(1, korpus=raw_text, smoothing=False)\n",
    "\n",
    "LM2A = ngram(2, korpus=raw_text, smoothing=False)\n",
    "LM2B = ngram(2, korpus=raw_text, smoothing=True)\n",
    "\n",
    "LM3A = ngram(3, korpus=raw_text, smoothing=False)\n",
    "LM3B = ngram(3, korpus=raw_text, smoothing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b41ef18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_bi_LM2A = sum(\n",
    "    len(counter)\n",
    "    for counter in LM2A.counts\n",
    "    if counter\n",
    ")\n",
    "\n",
    "sum_bi_LM2B = sum(\n",
    "    len(counter)\n",
    "    for counter in LM2B.counts\n",
    "    if counter\n",
    ")\n",
    "\n",
    "sum_tri_LM3A = sum(\n",
    "    len(counter)\n",
    "    for counter in LM3A.counts\n",
    "    if counter\n",
    ")\n",
    "\n",
    "sum_tri_LM3B = sum(\n",
    "    len(counter)\n",
    "    for counter in LM3B.counts\n",
    "    if counter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5555c30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Language Model 1--------\n",
      "|V|: 9339\n",
      "|Uni|: 9339\n",
      "--------Language Model 2--------\n",
      "|Bi|a: 9338\n",
      "Anteil nicht-null: 0.010707%\n",
      "\n",
      "|Bi|b: 9338\n",
      "--------Language Model 3--------\n",
      "|Tri|a: 102882\n",
      "Anteil nicht-null: 0.117961%\n",
      "\n",
      "|Tri|b: 102882\n"
     ]
    }
   ],
   "source": [
    "print(\"--------Language Model 1--------\")\n",
    "print(f\"|V|: {len(LM1.vocab)}\")\n",
    "print(f\"|Uni|: {len(LM1.counts.get(()))}\")\n",
    "print(\"--------Language Model 2--------\")\n",
    "print(f\"|Bi|a: {sum_bi_LM2A}\")\n",
    "ratio = sum_bi_LM2A / (len(LM2A.vocab) ** 2)\n",
    "print(f\"Anteil nicht-null: {ratio*100:2f}%\") ; print()\n",
    "print(f\"|Bi|b: {sum_bi_LM2B}\")\n",
    "print(\"--------Language Model 3--------\")\n",
    "print(f\"|Tri|a: {sum_tri_LM3A}\")\n",
    "ratio = sum_tri_LM3A / (len(LM3A.vocab) ** 2)\n",
    "print(f\"Anteil nicht-null: {ratio*100:2f}%\") ; print()\n",
    "print(f\"|Tri|b: {sum_tri_LM3B}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00137e73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
