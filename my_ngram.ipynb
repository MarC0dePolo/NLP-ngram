{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "01996b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Tuple\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5e6116b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ngram:\n",
    "    def __init__(self, n : int, korpus : str, smoothing = False):\n",
    "        self.n                          = n\n",
    "        self.smoothing                  = smoothing\n",
    "        self.toks                       = self._init_toks(korpus)\n",
    "\n",
    "        self.vocab, self.vocab_count    = self._init_vocab()\n",
    "        self.vocab_index                = {w:i for i,w in enumerate(self.vocab)}\n",
    "\n",
    "        self.counts                     = self._count()\n",
    "\n",
    "\n",
    "    def _init_toks(self, korpus):\n",
    "        # Alle Interpunktionszeichen außer \\w \\s ; . ? ! entfernen\n",
    "        text_no_p = re.sub(r\"[^\\w\\s;.?!]\", \"\", korpus)\n",
    "        # Leerzeichen vor jedem übrigen Punktionszeichen setzen\n",
    "        text_no_p = re.sub(r\"([;.?!])\", r\" \\1\", text_no_p)\n",
    "\n",
    "        # Satzgrenzen\n",
    "        text_no_p_ends = re.sub(r\"([?!;.])\", r\"\\1 </s>|||<s> \", text_no_p)\n",
    "        text_no_p_ends = \"<s> \" + text_no_p_ends + \" </s>\"\n",
    "\n",
    "        text_no_p_ends = text_no_p_ends.lower()\n",
    "\n",
    "        text_no_p_ends_list = re.findall(r'\\w+|<s>|</s>|[;.!?]', text_no_p_ends)\n",
    "\n",
    "        # Each sentence gets a whole list\n",
    "        toks = []\n",
    "        group = []\n",
    "\n",
    "        for tok in text_no_p_ends_list:\n",
    "            group.append(tok)\n",
    "\n",
    "            if tok == \"</s>\":\n",
    "                toks.append(group)\n",
    "                group = []\n",
    "\n",
    "        return toks\n",
    "\n",
    "    def _init_vocab(self):\n",
    "        # 1) Zähle alle Tokens\n",
    "        counter = Counter(tok for sentence in self.toks for tok in sentence)\n",
    "        \n",
    "        # 2) Sortiere nach Häufigkeit (absteigend)\n",
    "        items = counter.most_common()    # Liste von (token, count)\n",
    "        \n",
    "        # 3) Entpacke in zwei Listen\n",
    "        vocab, counts = zip(*items)\n",
    "        \n",
    "        return list(vocab), list(counts)\n",
    "\n",
    "\n",
    "    def _count(self):\n",
    "        \"\"\"\n",
    "        counts: Dict[ Tuple(context), Counter(next_word → count) ]\n",
    "        \"\"\"\n",
    "        counts = defaultdict(Counter)\n",
    "        for sent in self.toks:\n",
    "            for i in range(len(sent) - self.n + 1):\n",
    "                ctx  = tuple(sent[i:i + (self.n - 1)])\n",
    "                nxt  = sent[i + self.n - 1]\n",
    "                counts[ctx][nxt] += 1\n",
    "\n",
    "        if self.smoothing:\n",
    "            # Add-one Smoothing: für jeden Kontext und jedes Vokabel +1\n",
    "            for ctx in counts:\n",
    "                for w in self.vocab:\n",
    "                    counts[ctx][w] += 1\n",
    "\n",
    "        return counts\n",
    "    \n",
    "\n",
    "    def next_word(self, seed):\n",
    "        \"\"\"\n",
    "        Gibt genau ein Wort zurück, basierend auf dem letzten n-1 Kontext-Tokens.\n",
    "        \"\"\"\n",
    "        toks = seed.lower().split()\n",
    "        # Links mit <s> füllen, falls Seed zu kurz\n",
    "        while len(toks) < self.n - 1:\n",
    "            toks.insert(0, \"<s>\")\n",
    "        \n",
    "        ctx = tuple(toks[-(self.n - 1):])\n",
    "\n",
    "        # Hol den Counter für diesen Kontext (oder leeren Counter als Fallback)\n",
    "        counter = self.counts.get(ctx, None)\n",
    "        if not counter:\n",
    "            # unbekannter Kontext → gleichverteilt über ganzes Vokabular\n",
    "            return random.choice(self.vocab)\n",
    "\n",
    "        # Liste von möglichen Nachfolgern und ihren Counts\n",
    "        words, weights = zip(*counter.items())\n",
    "\n",
    "        # Ziehe gewichtet nach Counts (int-weights reichen)\n",
    "        return random.choices(words, weights=weights, k=1)[0]\n",
    "\n",
    "    def generate(self, seed: str, length: int) -> str:\n",
    "        toks = seed.lower().split()\n",
    "        # Padding links mit <s>\n",
    "        while self.n > 1 and len(toks) < self.n - 1:\n",
    "            toks.insert(0, \"<s>\")\n",
    "\n",
    "        for _ in range(length):\n",
    "            nxt = self.next_word(\" \".join(toks[-(self.n - 1):]))\n",
    "            toks.append(nxt)\n",
    "            if nxt == \"</s>\":\n",
    "                break\n",
    "\n",
    "        # Gib den Text ohne die Start-Markierungen zurück\n",
    "        return \" \".join(toks[self.n - 1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "736fc19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 10 Random <UNK> for Toks with 1 occourance\n",
    "\n",
    "# for i, (num, word) in enumerate(num_vocab):\n",
    "#     if num == 1:\n",
    "#         begin = i\n",
    "#         break\n",
    "\n",
    "# start_end_indexes = list(range(begin, len(num_vocab)))\n",
    "\n",
    "# choosen = []\n",
    "\n",
    "# for _ in range(10):\n",
    "#     rand_idx = random.choice(start_end_indexes)\n",
    "#     choosen.append(rand_idx)\n",
    "#     start_end_indexes.remove(rand_idx)\n",
    "\n",
    "# for i in choosen:\n",
    "#     num_vocab[i][1] = \"<UNK>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c33ba8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"\"\n",
    "\n",
    "for txt in os.listdir(\"korpus\"):\n",
    "    with open(f\"korpus/{txt}\", \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    raw_text += content + \" \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5197e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "LM1 = ngram(1, korpus=raw_text, smoothing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "679de3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LM2A = ngram(2, korpus=raw_text, smoothing=False)\n",
    "LM2B = ngram(2, korpus=raw_text, smoothing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "802e1dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LM3A = ngram(3, korpus=raw_text, smoothing=False)\n",
    "LM3B = ngram(3, korpus=raw_text, smoothing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "d569e4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ihr'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LM1.next_word(\"<s> es war\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "4188489a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "';'"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LM2A.next_word(\"<s> es war\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "05ede067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lobes'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LM2B.next_word(\"<s> es war\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "81043847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'es war mit freundlicher miene zum lachen und hacken vom sultan von'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LM2A.generate(\"<s> es war\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4a9f0445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'es war asche wort treibst staubwolke wozu wog glücklicherweise unglückliche ausgeruht nebenan'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LM2B.generate(\"<s> es war\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "477ccba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dies'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LM3A.next_word(\"<s> es war\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "6881cc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'drück'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LM3B.next_word(\"<s> es war\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "526e4202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'war das sichtbar abgenommen hatte . </s>'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LM3A.generate(\"<s> es war\", 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ec8e8281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'war weniger vorige gelebt verblich bildete bahre rang täglichen berührte idee herausforderung ostern früh eins daher'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LM3B.generate(\"<s> es war\", 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46182d32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
