{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01996b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Tuple\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6116b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ngram:\n",
    "    def __init__(self, n : int, korpus : str, smoothing = False):\n",
    "        self.n                          = n\n",
    "        self.smoothing                  = smoothing\n",
    "        self.toks                       = self.init_toks(korpus)\n",
    "\n",
    "        self.vocab, self.vocab_count    = self.init_vocab()\n",
    "\n",
    "        self.counts                     = self.count()\n",
    "\n",
    "\n",
    "    def init_toks(self, korpus) -> List[List[str]]:\n",
    "        # Alle Interpunktionszeichen außer \\w \\s ; . ? ! entfernen\n",
    "        text_no_p = re.sub(r\"[^\\w\\s;.?!]\", \"\", korpus)\n",
    "        # Leerzeichen vor jedem übrigen Punktionszeichen setzen\n",
    "        text_no_p = re.sub(r\"([;.?!])\", r\" \\1\", text_no_p)\n",
    "\n",
    "        # Satzgrenzen\n",
    "        text_no_p_ends = re.sub(r\"([?!;.])\", r\"\\1 </s>|||<s> \", text_no_p)\n",
    "        text_no_p_ends = \"<s> \" + text_no_p_ends + \" </s>\"\n",
    "\n",
    "        text_no_p_ends = text_no_p_ends.lower()\n",
    "        \n",
    "        text_no_p_ends_list = re.findall(r'</s>|<s>|\\w+|[;.!?]', text_no_p_ends)\n",
    "\n",
    "        toks = []\n",
    "        group = []\n",
    "\n",
    "        for tok in text_no_p_ends_list:\n",
    "            group.append(tok)\n",
    "\n",
    "        if tok == \"</s>\":\n",
    "            toks.append(group)\n",
    "            group = []\n",
    "\n",
    "\n",
    "        return toks\n",
    "    \n",
    "    def random_unk(self):\n",
    "        for i, num in enumerate(self.vocab_count):\n",
    "            if num == 1:\n",
    "                start_idx = i\n",
    "                break\n",
    "\n",
    "        choices = []\n",
    "\n",
    "        idx_range = range(start_idx, len(self.vocab_count))\n",
    "        for _ in range(10):\n",
    "            rnd_idx = random.choices(idx_range)\n",
    "            choices.append(rnd_idx)\n",
    "        \n",
    "        for i in rnd_idx:\n",
    "            for j, sent in enumerate(self.toks):\n",
    "                for k, w in enumerate(sent):\n",
    "                    if w == self.vocab[i]:\n",
    "                        self.toks[j][k] = \"<UNK>\"\n",
    "            \n",
    "            self.vocab[i] = \"<UNK>\"\n",
    "        \n",
    "        \n",
    "\n",
    "    def init_vocab(self):\n",
    "        counter = Counter(tok for sentence in self.toks for tok in sentence)\n",
    "        \n",
    "        items = counter.most_common()    # Liste von (token, count)\n",
    "        \n",
    "        vocab, vocab_count = zip(*items)\n",
    "        \n",
    "        return list(vocab), list(vocab_count)\n",
    "\n",
    "\n",
    "    def count(self):\n",
    "        \"\"\"\n",
    "        counts: Dict[ Tuple(context), Counter(next_word → count) ]\n",
    "        \"\"\" # Counter([1,1,1]) => \"Ich habe\": {1: 3}\n",
    "        counts = defaultdict(Counter)\n",
    "        for sent in self.toks:\n",
    "            for i in range(len(sent) - self.n + 1):\n",
    "                ctx  = tuple(sent[i:i + (self.n - 1)])\n",
    "                nxt  = sent[i + self.n - 1]\n",
    "                counts[ctx][nxt] += 1\n",
    "\n",
    "        if self.smoothing:\n",
    "            # Add-one Smoothing: für jeden Kontext und jede Vokabel +1\n",
    "            for ctx in counts:\n",
    "                for w in self.vocab:\n",
    "                    counts[ctx][w] += 1\n",
    "\n",
    "        return counts\n",
    "\n",
    "    def next_word(self, seed):\n",
    "        \"\"\"\n",
    "        Gibt genau ein Wort zurück\n",
    "        \"\"\"\n",
    "        toks = seed.lower().split(\" \")\n",
    "        # Padding mit <s>\n",
    "        while len(toks) < self.n - 1:\n",
    "            toks.insert(0, \"<s>\")\n",
    "        \n",
    "        ctx = tuple(toks[-(self.n - 1):])\n",
    "\n",
    "        # Hol den Counter für diesen Kontext\n",
    "        counter = self.counts.get(ctx, None)\n",
    "        if not counter:\n",
    "            # unbekannter Kontext => Nehme random Wort aus dem Vokabular\n",
    "            return random.choice(self.vocab)\n",
    "        \n",
    "        words, weights = zip(*counter.items())\n",
    "\n",
    "        # Nächstes Wort\n",
    "        return random.choices(words, weights=weights, k=1)[0]\n",
    "\n",
    "    def generate(self, seed: str, length: int) -> str:\n",
    "        toks = seed.lower().split()\n",
    "        # Padding links mit <s>\n",
    "        while self.n > 1 and len(toks) < self.n - 1:\n",
    "            toks.insert(0, \"<s>\")\n",
    "\n",
    "        for _ in range(length):\n",
    "            nxt = self.next_word(\" \".join(toks[-(self.n - 1):]))\n",
    "            toks.append(nxt)\n",
    "            if nxt == \"</s>\":\n",
    "                # toks.append(nxt)\n",
    "                break\n",
    "\n",
    "        # Gib den Text zurück\n",
    "        return \" \".join(toks)\n",
    "    \n",
    "    def len_grams(self):\n",
    "        if self.n == 1:\n",
    "            return len(self.counts.get(()))\n",
    "        \n",
    "        else:\n",
    "            return sum(len(counter) for counter in self.counts if counter)\n",
    "        \n",
    "    \n",
    "    def ppx(self, test_set : str) -> float:\n",
    "        test_set = self.init_toks(test_set)\n",
    "        \n",
    "        N = sum(\n",
    "            max(0, len(sent) - self.n + 1)\n",
    "            for sent in test_set\n",
    "        )\n",
    "\n",
    "        V = len(self.vocab)\n",
    "\n",
    "        log_sum = 0.0\n",
    "        for sent in test_set:\n",
    "            for i in range(len(sent) - self.n + 1):\n",
    "                ctx = tuple(sent[i:i + (self.n - 1)])\n",
    "                nxt = sent[i + self.n - 1]\n",
    "\n",
    "                # Falls Kontext nicht vorhanden -> 0\n",
    "                count_ctx_w = self.counts.get(ctx, Counter()).get(nxt, 0)\n",
    "                count_ctx = sum(self.counts.get(ctx, Counter()).values())\n",
    "\n",
    "                # Laplace add one\n",
    "                num = count_ctx_w + 1\n",
    "                # Vokabular addieren\n",
    "                denom = count_ctx + V              \n",
    "\n",
    "                prob = num / denom\n",
    "                log_sum += -math.log(prob)\n",
    "            \n",
    "\n",
    "        return math.exp(log_sum / N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c33ba8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"\"\n",
    "\n",
    "for txt in os.listdir(\"korpus\"):\n",
    "    with open(f\"korpus/{txt}\", \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    raw_text += content + \" \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d4c899",
   "metadata": {},
   "source": [
    "## Modelle trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5197e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "LM1 = ngram(1, korpus=raw_text, smoothing=False)\n",
    "\n",
    "LM2A = ngram(2, korpus=raw_text, smoothing=False)\n",
    "LM2B = ngram(2, korpus=raw_text, smoothing=True)\n",
    "\n",
    "LM3A = ngram(3, korpus=raw_text, smoothing=False)\n",
    "# LM3B = ngram(3, korpus=raw_text, smoothing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4a05fe",
   "metadata": {},
   "source": [
    "## LM Statistik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5555c30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|V|: 9339\n",
      "\n",
      "--------Language Model 1--------\n",
      "|Uni|: 9339\n",
      "\n",
      "--------Language Model 2--------\n",
      "|Bi|a: 9339\n",
      "Anteil nicht-null: 0.010708%\n",
      "\n",
      "|Bi|b: 9339\n",
      "--------Language Model 3--------\n",
      "|Tri|a: 102892\n",
      "Anteil nicht-null: 0.000013%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"|V|: {len(LM1.vocab)}\") ; print()\n",
    "\n",
    "print(\"--------Language Model 1--------\")\n",
    "print(f\"|Uni|: {LM1.len_grams()}\") ; print()\n",
    "\n",
    "print(\"--------Language Model 2--------\")\n",
    "print(f\"|Bi|a: {LM2A.len_grams()}\")\n",
    "ratio = LM2A.len_grams() / (len(LM2A.vocab) ** 2)\n",
    "print(f\"Anteil nicht-null: {ratio*100:2f}%\") ; print()\n",
    "print(f\"|Bi|b: {LM2B.len_grams()}\")\n",
    "\n",
    "print(\"--------Language Model 3--------\")\n",
    "print(f\"|Tri|a: {LM3A.len_grams()}\")\n",
    "ratio = LM3A.len_grams() / (len(LM3A.vocab) ** 3)\n",
    "print(f\"Anteil nicht-null: {ratio*100:2f}%\") ; print()\n",
    "\n",
    "# print(f\"|Tri|b: {sum_tri_LM3B}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560c62ae",
   "metadata": {},
   "source": [
    "## Text generierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "598db897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> diener hereinzutreten sünde zuge zerkratzen fast erkundigte d zurücksank auspacken'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LM1.generate(\"<s>\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f3ae417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> es war einmal willigte ausflug erbschaft seid dahinging sogleich leute ganz gewiß gewünscht'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LM2B.generate(\"<s> es war einmal\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "03397d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> es war einmal mitten im zimmer ; </s>'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LM3A.generate(\"<s> es war einmal\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d4c70811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'ein': 4, 'eine': 2, 'gemacht': 1, 'mitten': 1})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LM3A.counts.get((\"war\", \"einmal\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7464f11d",
   "metadata": {},
   "source": [
    "## Text Klassifikation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4517cdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"\"\"Es war einmal eine Königin. Anspruchsvoll war sie und nicht sehr schön, doch weil \n",
    "sie ihren Untertanen Süße und Glück versprach, schenkten sie ihr die besten Böden. Das \n",
    "Reich der Königin wuchs, aber bald wurde sie krank, und ihre Feinde nutzten ihre \n",
    "Schwäche. Unruhe regte sich im Volk, die Zweifel nahmen zu. Wie ist die Königin zu \n",
    "retten? Oder wäre es besser, sie sterben zu lassen?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "36190653",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"\"\"So ließe sie sich erzählen, die Geschichte der runzligen Zuckerrübe, der \"Königin der \n",
    "Feldfrüchte\", wie Bauern sie nennen. Märchenhaft war sowohl ihr Aufstieg in Deutschland und anderen Ländern Europas als auch der Wohlstand, den sie manchem Landwirt \n",
    "bescherte. Der aus ihr gewonnene Zucker verfeinerte eine Fülle von Lebensmitteln, kaum \n",
    "etwas kam noch ohne ihn aus. Inzwischen jedoch hat Zucker in unserer Nahrung ein \n",
    "solches Übermaß erreicht, dass er mehr Schaden als Beglückung verspricht. Zu viel Zucker \n",
    "kann zu Übergewicht führen, zu Diabetes, Herz-Kreislauf-Erkrankungen, Bluthochdruck. \n",
    "Selbst zwischen Zuckerkonsum und Krebs sehen einige Wissenschaftler Zusammenhänge.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e203d95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500.06876648965954\n",
      "1314.3432727520342\n"
     ]
    }
   ],
   "source": [
    "print(LM1.ppx(text1))\n",
    "print(LM1.ppx(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f14a6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1407.8475803904273"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LM2A.ppx(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bd5190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
